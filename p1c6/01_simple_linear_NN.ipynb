{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using pytorch torch.nn module to bulit neural networks\n",
    "PyTorch has a whole submodule dedicated to neural networks, called torch.nn. It\n",
    "contains the building blocks needed to create all sorts of neural network architectures.\n",
    "Those building blocks are called modules in PyTorch parlance (such building\n",
    "blocks are often referred to as layers in other frameworks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Buliding basic linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=1, out_features=1, bias=True)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model = nn.Linear(1, 1)\n",
    "linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mow we have an instance of nn.Linear with one input and one output feature. That\n",
    "only requires one weight and one bias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[-0.4664]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0791], requires_grad=True))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to get weight and bias of the defined model\n",
    "linear_model.weight, linear_model.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.5454], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "x = torch.ones(1)\n",
    "linear_model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any module in nn is written to produce outputs for a batch of multiple inputs at the\n",
    "same time. Thus, assuming we need to run nn.Linear on 10 samples, we can create an\n",
    "input tensor of size B × Nin, where B is the size of the batch and Nin is the number of\n",
    "input features, and run it once through the model. For example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5454],\n",
       "        [-0.5454],\n",
       "        [-0.5454],\n",
       "        [-0.5454],\n",
       "        [-0.5454],\n",
       "        [-0.5454],\n",
       "        [-0.5454],\n",
       "        [-0.5454],\n",
       "        [-0.5454],\n",
       "        [-0.5454]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones(10, 1)\n",
    "linear_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_c = [0.5, 14.0, 15.0, 28.0, 11.0, 8.0, 3.0, -4.0, 6.0, 13.0, 21.0]\n",
    "t_u = [35.7, 55.9, 58.2, 81.9, 56.3, 48.9, 33.9, 21.8, 48.4, 60.4, 68.4]\n",
    "t_c = torch.tensor(t_c)\n",
    "t_u = torch.tensor(t_u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([11]), torch.Size([11]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_c.shape, t_u.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "linear_model = nn.Linear(1, 1)\n",
    "# This method call replaces [params]\n",
    "optimizer = optim.SGD(linear_model.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**torch.optim** is a package implementing various optimization algorithms. To use **torch.optim** you have to construct an optimizer object, that will hold the current state and will update the parameters based on the computed gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[0.0887]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.3808], requires_grad=True)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to get the list of model parameters to be optimized\n",
    "# i.e 'Weight' and 'bias'\n",
    "list(linear_model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimizer is provided with a list of tensors that were defined with **requires_grad = True**—all Parameters are defined this way by definition, since they need to be optimized by gradient descent. When **training_loss.backward()** is called, grad is accumulated on the leaf nodes of the graph, which are precisely the parameters that were passed to the optimizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, the SGD optimizer has everything it needs. When **optimizer.step()**\n",
    "is called, it will iterate through each *Parameter* and change it by an amount proportional\n",
    "to what is stored in its grad attribute. Pretty clean design."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the training loop\n",
    "def training_loop(n_epochs, optimizer, model, loss_fn,\n",
    "                   t_u_train, t_u_val, t_c_train, t_c_val):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        t_p_train = model(t_u_train)\n",
    "        loss_train = loss_fn(t_p_train, t_c_train)\n",
    "        \n",
    "        t_p_val = model(t_u_val)\n",
    "        loss_val = loss_fn(t_p_val, t_c_val)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if epoch == 1 or epoch%1000 == 0:\n",
    "            print(\"Epoch:%d, Training loss:%.4f, Val loss:%.4f\" \n",
    "                  %(epoch, loss_train, loss_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[4.8900],\n",
       "         [5.5900],\n",
       "         [5.6300],\n",
       "         [3.5700],\n",
       "         [8.1900],\n",
       "         [3.3900],\n",
       "         [5.8200],\n",
       "         [4.8400],\n",
       "         [6.8400]]),\n",
       " torch.Size([9, 1]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_samples = t_u.shape[0]\n",
    "n_val = int(0.2 * n_samples)\n",
    "\n",
    "shuffled_indices = torch.randperm(n_samples)\n",
    "\n",
    "train_indices = shuffled_indices[:-n_val]\n",
    "val_indices = shuffled_indices[-n_val:]\n",
    "\n",
    "train_indices, val_indices\n",
    "\n",
    "t_u_train = t_u[train_indices].unsqueeze(-1)\n",
    "t_c_train = t_c[train_indices].unsqueeze(-1)\n",
    "\n",
    "t_u_val = t_u[val_indices].unsqueeze(-1)\n",
    "t_c_val = t_c[val_indices].unsqueeze(-1)\n",
    "\n",
    "t_un_train = 0.1 * t_u_train\n",
    "t_un_val = 0.1 * t_u_val\n",
    "\n",
    "t_un_train, t_u_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 5,  1,  4,  0,  3,  6,  2,  8, 10]),\n",
       " tensor([[48.9000],\n",
       "         [55.9000],\n",
       "         [56.3000],\n",
       "         [35.7000],\n",
       "         [81.9000],\n",
       "         [33.9000],\n",
       "         [58.2000],\n",
       "         [48.4000],\n",
       "         [68.4000]]))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_indices, t_u_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There’s one last bit that we can leverage from **torch.nn:** the loss. Indeed, nn comes with several common loss functions, among them **nn.MSELoss** (MSE stands for Mean Square Error), which is exactly what we defined earlier as our loss_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1, Training loss:121.7230, Val loss:56.1450\n",
      "Epoch:1000, Training loss:4.6240, Val loss:2.6424\n",
      "Epoch:2000, Training loss:2.7051, Val loss:4.1189\n",
      "Epoch:3000, Training loss:2.5460, Val loss:5.7409\n"
     ]
    }
   ],
   "source": [
    "linear_model = nn.Linear(1, 1)\n",
    "optimizer = optim.SGD(linear_model.parameters(), lr=1e-2)\n",
    "\n",
    "training_loop(n_epochs=3000,\n",
    "              optimizer=optimizer,\n",
    "              model=linear_model,\n",
    "              loss_fn=nn.MSELoss(),\n",
    "              t_u_train=t_un_train,\n",
    "              t_u_val=t_un_val,\n",
    "              t_c_train=t_c_train,\n",
    "              t_c_val=t_c_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Replacing the linear model with a simple neural network\n",
    "\n",
    "<img src=\"../images/img_chapter_06_linear_model_to_NN.png\" style=\"width:500px;height:50\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=1, out_features=13, bias=True)\n",
       "  (1): Tanh()\n",
       "  (2): Linear(in_features=13, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_model = nn.Sequential(nn.Linear(1, 13),\n",
    "                          nn.Tanh(),\n",
    "                          nn.Linear(13, 1))\n",
    "seq_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([13, 1]), torch.Size([13]), torch.Size([1, 13]), torch.Size([1])]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspecting the parameters\n",
    "[param.shape for param in seq_model.parameters()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When inspecting parameters of a model\n",
    "made up of several submodules, it is handy to be able to identify parameters by name.\n",
    "There’s a method for that, called *named_parameters*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.weight torch.Size([13, 1])\n",
      "0.bias torch.Size([13])\n",
      "2.weight torch.Size([1, 13])\n",
      "2.bias torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "for name, param in seq_model.named_parameters():\n",
    "    print(name, param.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The name of each module in *Sequential* is just the ordinal with which the module\n",
    "appears in the arguments. Interestingly, *Sequential* also accepts an *OrderedDict*, in\n",
    "which we can name each module passed to *Sequential*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "seq_model = nn.Sequential(OrderedDict([\n",
    "                        ('hidden_linear', nn.Linear(1, 8)),\n",
    "                        ('hidden_activation', nn.Tanh()),\n",
    "                        ('output_linear', nn.Linear(8, 1))\n",
    "                        ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (hidden_linear): Linear(in_features=1, out_features=8, bias=True)\n",
       "  (hidden_activation): Tanh()\n",
       "  (output_linear): Linear(in_features=8, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden_linear.weight torch.Size([8, 1])\n",
      "hidden_linear.bias torch.Size([8])\n",
      "output_linear.weight torch.Size([1, 8])\n",
      "output_linear.bias torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "for name, param in seq_model.named_parameters():\n",
    "    print(name, param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.9657],\n",
       "        [-0.0189],\n",
       "        [ 0.2885],\n",
       "        [ 0.9948],\n",
       "        [-0.5676],\n",
       "        [-0.2174],\n",
       "        [ 0.3317],\n",
       "        [-0.5404]], requires_grad=True)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can also access a particular Parameter\n",
    "# by using submodules as attributes:\n",
    "seq_model.hidden_linear.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1, Training loss:212.0688, Val loss:94.2214\n",
      "Epoch:1000, Training loss:4.9337, Val loss:3.8363\n",
      "Epoch:2000, Training loss:4.2538, Val loss:12.2038\n",
      "Epoch:3000, Training loss:2.2067, Val loss:10.6045\n",
      "Epoch:4000, Training loss:1.7022, Val loss:10.2019\n",
      "Epoch:5000, Training loss:1.4493, Val loss:9.5445\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.SGD(seq_model.parameters(), lr=1e-3)\n",
    "\n",
    "training_loop(\n",
    "n_epochs = 5000,\n",
    "optimizer = optimizer,\n",
    "model = seq_model,\n",
    "loss_fn = nn.MSELoss(),\n",
    "t_u_train = t_un_train,\n",
    "t_u_val = t_un_val,\n",
    "t_c_train = t_c_train,\n",
    "t_c_val = t_c_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output tensor([[15.6178],\n",
      "        [-0.9672]], grad_fn=<AddmmBackward>)\n",
      "answer tensor([[13.],\n",
      "        [-4.]])\n",
      "hidden tensor([[-2.0741e-03],\n",
      "        [-5.9225e+00],\n",
      "        [ 5.2238e+00],\n",
      "        [-3.8859e-02],\n",
      "        [-5.7606e+00],\n",
      "        [-5.6466e+00],\n",
      "        [ 4.1701e-02],\n",
      "        [-5.1872e-02]])\n"
     ]
    }
   ],
   "source": [
    "print('output', seq_model(t_un_val))\n",
    "print('answer', t_c_val)\n",
    "print('hidden', seq_model.hidden_linear.weight.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Comparing to the linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x15b1d48a9c8>]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "t_range = torch.arange(20., 90.).unsqueeze(-1)\n",
    "\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "plt.xlabel(\"Fahrenheit\")\n",
    "plt.ylabel(\"Celsius\")\n",
    "plt.plot(t_u.numpy(), t_c.numpy(), 'o', 'b')\n",
    "plt.plot(t_range.numpy(),seq_model(0.1*t_range).detach().numpy(), 'kx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70, 1)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_range.numpy().shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([35.7, 55.9, 58.2, 81.9, 56.3, 48.9, 33.9, 21.8, 48.4, 60.4, 68.4],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_u.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[30.40131 ],\n",
       "       [30.401342],\n",
       "       [30.401356],\n",
       "       [30.401363],\n",
       "       [30.401363],\n",
       "       [30.401367],\n",
       "       [30.401367],\n",
       "       [30.401367],\n",
       "       [30.401367],\n",
       "       [30.401367],\n",
       "       [30.401367],\n",
       "       [30.401367],\n",
       "       [30.401367],\n",
       "       [30.401367],\n",
       "       [30.401367],\n",
       "       [30.401367],\n",
       "       [30.401367],\n",
       "       [30.401367],\n",
       "       [30.401367],\n",
       "       [30.401367],\n",
       "       [30.401367],\n",
       "       [30.401367],\n",
       "       [30.401367],\n",
       "       [30.401367],\n",
       "       [30.401367],\n",
       "       [30.401367],\n",
       "       [30.401367],\n",
       "       [30.401367],\n",
       "       [30.401367],\n",
       "       [30.401367],\n",
       "       [30.401367],\n",
       "       [30.401367],\n",
       "       [30.401367],\n",
       "       [30.401367],\n",
       "       [30.401367],\n",
       "       [30.401367],\n",
       "       [30.401367],\n",
       "       [30.401367],\n",
       "       [30.401367],\n",
       "       [30.401367],\n",
       "       [30.401367],\n",
       "       [30.401367],\n",
       "       [30.401367],\n",
       "       [30.401367],\n",
       "       [30.401367],\n",
       "       [30.401367],\n",
       "       [30.401367],\n",
       "       [30.401367],\n",
       "       [30.401367],\n",
       "       [30.401367],\n",
       "       [30.401367],\n",
       "       [30.401367],\n",
       "       [30.401367],\n",
       "       [30.401367],\n",
       "       [30.401367],\n",
       "       [30.401367],\n",
       "       [30.401367],\n",
       "       [30.401367],\n",
       "       [30.401367],\n",
       "       [30.401367],\n",
       "       [30.401367],\n",
       "       [30.401367],\n",
       "       [30.401367],\n",
       "       [30.401367],\n",
       "       [30.401367],\n",
       "       [30.401367],\n",
       "       [30.401367],\n",
       "       [30.401367],\n",
       "       [30.401367],\n",
       "       [30.401367]], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_model(t_range).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
